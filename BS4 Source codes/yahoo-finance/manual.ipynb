{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63089e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden Ocean Group Limited (GOGL)\n",
      "Johnson & Johnson (JNJ)\n",
      "BHP Group Limited (BHP)\n",
      "PPL Corporation (PPL)\n",
      "The Trade Desk, Inc. (TTD)\n",
      "Huntington Bancshares Incorporated (HBAN)\n",
      "Huntsman Corporation (HUN)\n",
      "Hewlett Packard Enterprise Company (HPE)\n",
      "Harmony Gold Mining Company Limited (HMY)\n",
      "Rocket Lab USA, Inc. (RKLB)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pprint\n",
    "import re\n",
    "import pyperclip\n",
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('h1', attrs={'class': 'D(ib) Fz(18px)'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a811de13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NasdaqGS - NasdaqGS Real Time Price. Currency in USD\n",
      "NYSE - NYSE Delayed Price. Currency in USD\n",
      "NYSE - NYSE Delayed Price. Currency in USD\n",
      "NYSE - NYSE Delayed Price. Currency in USD\n",
      "NasdaqGM - NasdaqGM Real Time Price. Currency in USD\n",
      "NasdaqGS - NasdaqGS Real Time Price. Currency in USD\n",
      "NYSE - Nasdaq Real Time Price. Currency in USD\n",
      "NYSE - NYSE Delayed Price. Currency in USD\n",
      "NYSE - NYSE Delayed Price. Currency in USD\n",
      "NasdaqCM - NasdaqCM Real Time Price. Currency in USD\n"
     ]
    }
   ],
   "source": [
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('div', attrs={'class': 'C($tertiaryColor) Fz(12px)'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d603a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.37\n",
      "177.74\n",
      "75.63\n",
      "28.44\n",
      "73.33\n",
      "15.33\n",
      "37.88\n",
      "17.56\n",
      "4.9200\n",
      "8.29\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pprint\n",
    "import re\n",
    "import pyperclip\n",
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('fin-streamer', attrs={'class': 'Fw(b) Fz(36px) Mb(-4px) D(ib)'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99be919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+0.16\n",
      "-0.09\n",
      "+0.04\n",
      "+0.67\n",
      "+4.44\n",
      "+0.24\n",
      "-0.01\n",
      "+0.18\n",
      "-0.0100\n",
      "+0.65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('fin-streamer', attrs={'data-test': 'qsp-price-change'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1883795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+0.29', '(+5.78%)']\n",
      "['+0.10', '(+1.06%)']\n",
      "['+0.30', '(+3.72%)']\n",
      "['+1.33', '(+4.41%)']\n",
      "['+4.33', '(+3.21%)']\n",
      "['-1.70', '(-3.41%)']\n",
      "['+1.03', '(+3.70%)']\n",
      "['-0.02', '(-0.37%)']\n",
      "['+2.45', '(+2.23%)']\n",
      "['+0.32', '(+2.48%)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/IS?p=IS',\n",
    "'https://finance.yahoo.com/quote/UMC?p=UMC',\n",
    "'https://finance.yahoo.com/quote/NU?p=NU',\n",
    "'https://finance.yahoo.com/quote/FL?p=FL',\n",
    "'https://finance.yahoo.com/quote/NKE?p=NKE',\n",
    "'https://finance.yahoo.com/quote/CFG?p=CFG',\n",
    "'https://finance.yahoo.com/quote/VICI?p=VICI',\n",
    "'https://finance.yahoo.com/quote/SID?p=SID',\n",
    "'https://finance.yahoo.com/quote/MDT?p=MDT',\n",
    "'https://finance.yahoo.com/quote/DB?p=DB',]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find_all('fin-streamer', attrs={'class': 'Fw(500) Pstart(8px) Fz(24px)'})\n",
    "\n",
    "    #print(h1.get_text())\n",
    "    doctor_n = []\n",
    "\n",
    "    for title in h1:\n",
    "        doctor_n.append(title.text.strip())\n",
    "    print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef213b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(+5.78%)\n",
    "(+1.06%)\n",
    "(+3.72%)\n",
    "(+4.41%)\n",
    "(+3.21%)\n",
    "(-3.41%)\n",
    "(+3.70%)\n",
    "(-0.37%)\n",
    "(+2.23%)\n",
    "(+2.48%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff6d0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.21\n",
      "177.83\n",
      "75.59\n",
      "27.77\n",
      "68.89\n",
      "15.09\n",
      "37.89\n",
      "17.38\n",
      "4.9300\n",
      "7.64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'PREV_CLOSE-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80db4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.10\n",
      "178.62\n",
      "74.25\n",
      "27.85\n",
      "70.63\n",
      "15.26\n",
      "38.16\n",
      "17.58\n",
      "4.7300\n",
      "7.73\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'OPEN-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5cd1781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 x 1800\n",
      "175.42 x 900\n",
      "76.51 x 1000\n",
      "28.39 x 1400\n",
      "0.00 x 800\n",
      "0.00 x 2900\n",
      "37.82 x 900\n",
      "16.66 x 800\n",
      "4.9500 x 1300\n",
      "0.00 x 2200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'BID-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3061ae38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 x 1000\n",
      "179.50 x 800\n",
      "77.22 x 2200\n",
      "28.38 x 3200\n",
      "0.00 x 800\n",
      "0.00 x 2900\n",
      "37.83 x 900\n",
      "0.00 x 3000\n",
      "0.0000 x 1000\n",
      "0.00 x 1800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'ASK-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "374fce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.40 - 12.39\n",
      "176.80 - 179.40\n",
      "73.47 - 75.76\n",
      "27.77 - 28.49\n",
      "69.54 - 73.96\n",
      "15.12 - 15.43\n",
      "37.72 - 38.46\n",
      "17.38 - 17.66\n",
      "4.6650 - 4.9350\n",
      "7.67 - 8.39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'DAYS_RANGE-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a342a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.62 - 13.09\n",
      "155.72 - 179.92\n",
      "51.88 - 82.07\n",
      "25.27 - 30.72\n",
      "46.71 - 114.09\n",
      "13.01 - 17.79\n",
      "24.10 - 41.65\n",
      "12.99 - 17.76\n",
      "3.0000 - 5.7600\n",
      "7.51 - 21.34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'FIFTY_TWO_WK_RANGE-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec4e3fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,821,384\n",
      "5,891,968\n",
      "4,325,127\n",
      "7,549,273\n",
      "5,641,616\n",
      "7,172,264\n",
      "1,067,839\n",
      "5,827,593\n",
      "7,801,277\n",
      "4,002,429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'TD_VOLUME-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "404d764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,526,504\n",
      "7,981,850\n",
      "6,021,254\n",
      "6,470,003\n",
      "6,881,173\n",
      "12,925,645\n",
      "2,663,034\n",
      "11,198,442\n",
      "8,316,459\n",
      "4,224,567\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbbe3644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.479B\n",
      "467.389B\n",
      "274.757B\n",
      "20.914B\n",
      "35.553B\n",
      "22.149B\n",
      "8.125B\n",
      "22.83B\n",
      "3.064B\n",
      "3.853B\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'MARKET_CAP-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "004124dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53\n",
      "22.76\n",
      "11.37\n",
      "N/A\n",
      "261.89\n",
      "17.03\n",
      "8.02\n",
      "6.28\n",
      "23.32\n",
      "N/A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'PE_RATIO-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63fb2ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 31, 2022\n",
      "Apr 19, 2022\n",
      "N/A\n",
      "May 04, 2022 - May 09, 2022\n",
      "May 09, 2022 - May 13, 2022\n",
      "Apr 21, 2022\n",
      "Apr 28, 2022 - May 02, 2022\n",
      "May 30, 2022 - Jun 03, 2022\n",
      "N/A\n",
      "N/A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'EARNINGS_DATE-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4901d1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.65\n",
      "186.53\n",
      "75.20\n",
      "30.82\n",
      "96.32\n",
      "17.78\n",
      "46.17\n",
      "18.16\n",
      "3.32\n",
      "18.86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d257a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73\n",
      "7.81\n",
      "6.65\n",
      "-1.94\n",
      "0.28\n",
      "0.90\n",
      "4.72\n",
      "2.80\n",
      "0.2110\n",
      "-0.56\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'EPS_RATIO-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urls = ['https://finance.yahoo.com/quote/GOGL?p=GOGL',\n",
    "'https://finance.yahoo.com/quote/JNJ?p=JNJ',\n",
    "'https://finance.yahoo.com/quote/BHP?p=BHP',\n",
    "'https://finance.yahoo.com/quote/PPL?p=PPL',\n",
    "'https://finance.yahoo.com/quote/TTD?p=TTD',\n",
    "'https://finance.yahoo.com/quote/HBAN?p=HBAN',\n",
    "'https://finance.yahoo.com/quote/HUN?p=HUN',\n",
    "'https://finance.yahoo.com/quote/HPE?p=HPE',\n",
    "'https://finance.yahoo.com/quote/HMY?p=HMY',\n",
    "'https://finance.yahoo.com/quote/RKLB?p=RKLB',\n",
    "]\n",
    "#scrape elements\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    #print titles only\n",
    "    h1 = soup.find('td', attrs={'data-test': 'EPS_RATIO-value'})\n",
    "    print(h1.get_text())\n",
    "    #doctor_n = []\n",
    "\n",
    "    #for title in h1:\n",
    "    #    doctor_n.append(title.text.strip())\n",
    "    #print(doctor_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
